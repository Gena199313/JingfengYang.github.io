---
layout: default 
---
<header class="bloghead">
    <h1 class="bloghead-title">
    <a href="{{ site.url }}/">{{ site.name }}<span>&#39;s homepage</span></a>
  </h1>
    <nav class="bloghead-nav">
        {% for nav in site.nav %}
        <a href="{{ nav.href }}">{{ nav.name }}<span> &nbsp;/&nbsp; </span></a> {% endfor %}
    </nav>
</header>
<div class="content">
    <a name="bio"></a>
    <div class="post-list">
        <h2 class="post-title">
        Bio
    	</h2> 
        <p>I am an Applied Research Scientist at <a href="https://amazonsearchqu.github.io/" style="color:#4133ff;">Amazon Search</a>. I received M.S. in Computer Science (Machine Learning Specialization) at <a href="https://www.gatech.edu/" style="color:#4133ff;">Georgia Tech</a> in 2021, where I worked with Prof. <a href="https://www.cc.gatech.edu/~dyang888/index.html" style="color:#4133ff;">Diyi Yang</a> at SALT lab. Before that,  I received B.S. in Biological Science and Computer Science at <a href="http://english.pku.edu.cn/" style="color:#4133ff;">Peking University</a> in 2019, where I worked with Prof. <a href="http://123.56.88.210/" style="color:#4133ff;">Sujian Li</a>. In summer 2018, I worked as a research intern with Prof. <a href="http://homepages.inf.ed.ac.uk/bonnie/" style="color:#4133ff;">Bonnie Webber</a> at <a href="https://www.ed.ac.uk/" style="color:#4133ff;">the University of Edinburgh</a>. I also did research as an intern at <a href="https://amazonsearchqu.github.io/" style="color:#4133ff;">Amazon</a>, <a href="https://research.google/" style="color:#4133ff;">Google</a> and <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/" style="color:#4133ff;">Microsoft</a>, and conducted software development while interning at <a href="https://www.amazon.jobs/en/location/san-francisco-bay-area-ca" style="color:#4133ff;">Amazon</a>. </p>
            
        <p> I have a broad interest in Natural Language Processing and Machine Learning. My research goal is to 1) solve the data scarcity problem, 2) improve the generalization ability of models, and 3) design controllable and interpretable models,
            by 1) using unlabeled, out-of-domain or augmented text data, 2) incorporating external knowledge or inductive biases (e.g. intermediate abstractions, model architecture biases etc.) into models, and 3) pretraining in large scale.</p>

        <p> Specifically, I'm trying to achieve this goal in 1) text generation, 2) semantic parsing, and 3) multilingual NLP.

        <p> Recent advances in the field always make me rethink the utility of inductive biases in the future, considering that the effect of structral biases are decreasing with larger pretrained unified multimodal, multitask, multilingual Transformer models. 

        <p> I studied a lot about life science when I was an undergraduate, thus I'm also excited about any opportunities of leveraging AI to advance science (especially biological science and healthcare).    

        <p> I am open to any type of coffee chat. If you are interested in talking with me, feel free to send me an email.

    </div>
    <a name="news"></a>
    <div class="post-list">
        <h2 class="post-title">
        News
        </h2> 
        <p><b>Feb 23th, 2022:</b> Our paper "TableFormer: Robust Transformer Modeling for Table-Text Encoding." is accepted at ACL 2022. </p>
        <p><b>Jan 17th, 2022:</b> I returned to Amazon Search as an applied research scientist. </p>
        <p><b>Sep 27th, 2021:</b> I started my applied scientist internship at Amazon. </p>
        <p><b>Aug 26th, 2021:</b> Our paper "Frustratingly Simple but Surprisingly Strong: Using Language-Independent Features for Zero-shot Cross-lingual Semantic Parsing." is accepted at EMNLP 2021. </p>
        <p><b>Aug 26th, 2021:</b> Our paper "WIKIBIAS: Detecting Multi-Span Subjective Biases in Language." is accepted at EMNLP 2021 Findings. </p>
        <p><b>Jul 12th, 2021:</b> I started my research internship at Google. </p>
        <p><b>Mar 28th, 2021:</b> Gave some lectures for <a href="https://sites.google.com/view/nlp-bootcamp-s21/home" style="color:#4133ff;">NLP bootcamp</a> as a TA. </p>
        <p><b>Feb 15th, 2021:</b> Gave a lecture on PyTorch as head TA in <a href="https://www.cc.gatech.edu/classes/AY2021/cs4650_spring/" style="color:#4133ff;">CS-4650 Natural Language Processing.</a> <a href="https://www.cc.gatech.edu/classes/AY2021/cs4650_spring/slides/Introduction_to_PyTorch.pdf" style="color:#4133ff;">[Slides]</a></p>
        <p><b>Sep 15th, 2020:</b> Our paper "Planning and Generating Natural and Diverse Disfluent Texts as Augmentation for Disfluency Detection." is accepted at EMNLP 2020. </p>
        <p><b>Sep 2nd, 2020:</b> Gave a lecture on Deep Learning as a TA in <a href="https://www.cc.gatech.edu/classes/AY2021/cs7650_fall/" style="color:#4133ff;">CS-4650/7650 Natural Language Processing.</a> <a href="https://www.cc.gatech.edu/classes/AY2021/cs7650_fall/slides/Introduction_to_NN.pdf" style="color:#4133ff;">[Slides]</a></p>
    </div>
    <a name="education"></a>
    <div class="post-list">
        <h2 class="post-title">
        Education
    	</h2> 
        <p>Master of Science: Computer Science, Georgia Tech, Atlanta, America.  Aug 2019 - May 2021.</p>
        <p>Bachelor of Science: Computer Science and Biological Science, Peking University, Beijing, China.  Sep 2015 - July 2019.</p>
    </div>
    <a name="publications"></a>
    <div class="post-list">
        <h2 class="post-title">
        Publications 
        </h2> 

        <ul>
            <li><b>Jingfeng Yang</b>, Aditya Gupta, Shyam Upadhyay, Luheng He, Rahul Goel, Shachi Paul. 2022. <b>TableFormer: Robust Transformer Modeling for Table-Text Encoding.</b> In ACL' 2022. <a href="" style="color:#4133ff;">[Paper]</a> <a href="" style="color:#4133ff;">[Code]</a> </li>
            <li><b>Jingfeng Yang</b>, Federico Fancellu, Bonnie Webber, Diyi Yang. 2021. <b>Frustratingly Simple but Surprisingly Strong: Using Language-Independent Features for Zero-shot Cross-lingual Semantic Parsing.</b> In EMNLP' 2021 (Short). <a href="https://aclanthology.org/2021.emnlp-main.472.pdf" style="color:#4133ff;">[Paper]</a> <a href="https://github.com/JingfengYang/Multilingual-DRS-Semantic-parsing" style="color:#4133ff;">[Code]</a> </li>
            <li>Yang Zhong, <b>Jingfeng Yang</b>, Wei Xu, Diyi Yang. 2021. <b>WIKIBIAS: Detecting Multi-Span Subjective Biases in Language.</b> In EMNLP' 2021 (Findings). <a href="https://aclanthology.org/2021.findings-emnlp.155.pdf" style="color:#4133ff;">[Paper]</a> </li>
            <li><b>Jingfeng Yang</b>, Zhaoran Ma, Diyi Yang. 2020. <b>Planning and Generating Natural and Diverse Disfluent Texts as Augmentation for Disfluency Detection.</b> In EMNLP' 2020. <a href="https://www.aclweb.org/anthology/2020.emnlp-main.113/" style="color:#4133ff;">[Paper]</a> <a href="https://github.com/GT-SALT/Disfluency-Generation-and-Detection" style="color:#4133ff;">[Code]</a></li>
            <li><b>Jingfeng Yang</b>, Sujian Li. 2018. <b>Chinese Discourse Segmentation Using Bilingual Discourse Commonality.</b> Preprint. <a href="https://arxiv.org/abs/1809.01497" style="color:#4133ff;">[Paper]</a> </li>
	        <li>Yizhong Wang, Sujian Li, <b>Jingfeng Yang</b>. 2018. <b>Toward Fast and Accurate Neural Discourse Segmentation.</b> EMNLP' 2018. <a href="https://www.aclweb.org/anthology/D18-1116" style="color:#4133ff;">[Paper]</a></li>
	        <li>Yizhong Wang, Sujian Li, <b>Jingfeng Yang</b>, Xu Sun, Houfeng Wang. 2017. <b>Tag-enhanced tree-structured neural networks for implicit discourse relation classification.</b> In The 8thÂ International Joint Conference on Natural Language Processing (IJCNLP' 2017). <a href="https://arxiv.org/abs/1803.01165" style="color:#4133ff;">[Paper]</a></li>

        </ul>
        </div>

    <a name="service"></a>
    <div class="post-list">
            <h2 class="post-title">
            Service
            </h2> 
        <p>Reviewer: ACL Rolling Review, NAACL' 2021</p>
    </div>
    <a name="research"></a>
    <div class="post-list">
        <h2 class="post-title">
        Research Experiences
    	</h2> 
	<p>Research Assistant in College of Computing, Georgia Institute of Technology. Advisor: <a href="https://www.cc.gatech.edu/~dyang888/index.html" style="color:#4133ff;">Diyi Yang</a>. Aug 2019 - May 2021. </p>
    <p>Visiting Researcher in Institute for Language, Cognition and Computation, The University of Edinburgh. Advisor: <a href="http://homepages.inf.ed.ac.uk/bonnie/" style="color:#4133ff;">Bonnie Webber</a>. July 2018 - Sep 2018. </p>
	<p>Research Assistant in Department of Computational Linguistics, Peking University. Advisor: <a href="http://123.56.88.210" style="color:#4133ff;">Sujian Li</a>. July 2017 - June 2019.</p>
    </div>
    <a name="work"></a>
    <div class="post-list">
        <h2 class="post-title">
        Industry Experiences
        </h2> 
        <p>Applied Scientist Intern, Amazon, Palo Alto (Virtual). Mentors: <a href="https://hmjianggatech.github.io/" style="color:#4133ff;">Haoming Jiang</a>, <a href="https://danqingz.github.io/" style="color:#4133ff;">Danqing Zhang</a>, <a href="https://scholar.google.com/citations?user=P-mBKNYAAAAJ&hl=zh-CN" style="color:#4133ff;">Qingyu Yin</a>. Sep 2021 - Dec 2021. </p>
        <p>Research Intern, Google, Mountain View (Virtual). Collaborators: <a href="https://research.google/people/AdityaGupta/" style="color:#4133ff;">Aditya Gupta</a>,  <a href="https://scholar.google.com/citations?user=i7lw4LwAAAAJ&hl=en" style="color:#4133ff;">Shyam Upadhyay</a>, <a href="https://scholar.google.com/citations?user=XVVvabUAAAAJ&hl=en" style="color:#4133ff;">Luheng He</a>, <a href="https://scholar.google.com/citations?user=e6uk9EAAAAAJ&hl=en" style="color:#4133ff;">Rahul Goel</a>, <a href="https://scholar.google.com/citations?user=a_95_VkAAAAJ&hl=en" style="color:#4133ff;">Shachi Paul</a>. July 2021 - Sep 2021.</p>
        <p>Software Development Engineer Intern, Amazon, San Francisco (Virtual). May 2020 - July 2020. </p>
        <p>Research and Software Engineer Intern, Microsoft Research Asia, Beijing, China. Mentor: <a href="https://aclanthology.org/people/j/jin-ge-yao/" style="color:#4133ff;">Jin-ge Yao</a>. December 2018 - March 2019. </p>
    </div>
    <a name="teaching"></a>
    <div class="post-list">
        <h2 class="post-title">
        Teaching Experiences
        </h2> 
        <p>Teaching Assitant for Coding Support, POLS-585 Text as Data, Emory University, Atlanta. June 2021 - July 2021. </p>
        <p>Head Teaching Assistant, <a href="https://www.cc.gatech.edu/classes/AY2021/cs4650_spring/" style="color:#4133ff;">CS-4650 Natural Language Processing</a>, Georgia Institue of Technology, Atlanta. Spring 2021. </p>
        <p>Teaching Assistant, <a href="https://www.cc.gatech.edu/classes/AY2021/cs7650_fall/" style="color:#4133ff;">CS-4650/7650 Natural Language Processing</a>, Georgia Institue of Technology, Atlanta. Fall 2020. </p>
	    <p>Teaching Assistant, <a href="https://www.cc.gatech.edu/classes/AY2020/cs7650_spring/" style="color:#4133ff;">CS-4650/7650 Natural Language Processing</a>, Georgia Institue of Technology, Atlanta. Spring 2020. </p>
    </div>
    
    <a name="awards"></a>
    <div class="post-list">
        <h2 class="post-title">
        Awards 
    	</h2> 
        <p>May 4th Fellowship, 2016-2017.</p>
	    <p>Kwang-Hua Fellowship, 2015-2016.</p>
	    <p>Merit Student of Peking University, 2016-2017, 2015-2016.</p>
	    <p>Silver medalist in Chinese Mathematics Olympiad (CMO), 2015.</p>
	
    </div>

    
</div>
